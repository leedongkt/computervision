{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 실습1\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import sys\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "drive_path = \"/gdrive/My Drive/yolo/Recognition/\"\n",
        "\n",
        "def construct_yolo_v3():\n",
        "    f = open(drive_path + 'coco_names.txt', 'r')\n",
        "    class_names = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    model = cv.dnn.readNet(drive_path +'yolov3.weights', drive_path +'yolov3.cfg')\n",
        "    layer_names = model.getLayerNames()\n",
        "    out_layers = [layer_names[i - 1] for i in model.getUnconnectedOutLayers()]\n",
        "\n",
        "    return model, out_layers, class_names\n",
        "\n",
        "def yolo_detect(img, yolo_model, out_layers):\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "    test_img = cv.dnn.blobFromImage(img, 1.0 / 256, (448, 448), (0, 0, 0), swapRB=True)\n",
        "\n",
        "    yolo_model.setInput(test_img)\n",
        "    output3 = yolo_model.forward(out_layers)\n",
        "\n",
        "    box, conf, id = [], [], []\n",
        "\n",
        "    for output in output3:\n",
        "        for vec85 in output:\n",
        "            scores = vec85[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                centerx, centery = int(vec85[0] * width), int(vec85[1] * height)\n",
        "                w, h = int(vec85[2] * width), int(vec85[3] * height)\n",
        "                x, y = int(centerx - w / 2), int(centery - h / 2)\n",
        "                box.append([x, y, x + w, y + h])\n",
        "                conf.append(float(confidence))\n",
        "                id.append(class_id)\n",
        "\n",
        "    ind = cv.dnn.NMSBoxes(box, conf, 0.5, 0.4)\n",
        "    objects = [box[i] + [conf[i]] + [id[i]] for i in range(len(box)) if i in ind]\n",
        "\n",
        "    return objects\n",
        "\n",
        "model, out_layers, class_names = construct_yolo_v3()\n",
        "colors = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
        "\n",
        "img = cv.imread(drive_path +'soccer.jpg')\n",
        "if img is None: sys.exit(\"파일이 없습니다.\")\n",
        "\n",
        "res = yolo_detect(img, model, out_layers)\n",
        "\n",
        "for i in range(len(res)):\n",
        "    x1, y1, x2, y2, confidence, id = res[i]\n",
        "    text = str(class_names[id]) + ':%.3f' % confidence\n",
        "    cv.rectangle(img, (x1, y1), (x2, y2), colors[id], 2)\n",
        "    cv.putText(img, text, (x1, y1 + 30), cv.FONT_HERSHEY_PLAIN, 1.5, colors[id], 2)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "ZzLgokdRW6uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "07pNHFPaXbh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#실습 4번\n",
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import random\n",
        "import cv2 as cv\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "drive_path = \"/gdrive/My Drive/dataset/datasets2/oxford_pets/\"\n",
        "\n",
        "\n",
        "input_dir = drive_path + \"/images/images\"\n",
        "target_dir = drive_path + \"/annotations/annotations/trimaps\"\n",
        "img_siz=(160,160)\n",
        "n_class=3\n",
        "batch_siz=32\n",
        "\n",
        "img_paths = sorted([os.path.join(input_dir,f) for f in os.listdir(input_dir) if f.endswith('.jpg')])\n",
        "label_paths = sorted([os.path.join(target_dir,f) for f in os.listdir(target_dir) if f.endswith('.png') and not f.startswith('.')])\n",
        "\n",
        "class OxfordPets(keras.utils.Sequence):\n",
        "    def __init__(self,batch_size,img_size,img_paths,label_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.img_paths = img_paths\n",
        "        self.label_paths = label_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_paths)//self.batch_size\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        i = idx*self.batch_size\n",
        "        batch_img_paths = self.img_paths[i:i+self.batch_size]\n",
        "        batch_label_paths = self.label_paths[i:i+self.batch_size]\n",
        "        x= np.zeros((self.batch_size,)+self.img_size+(3,),dtype=\"float32\")\n",
        "        for j,path in enumerate(batch_img_paths):\n",
        "            img = load_img(path,target_size = self.img_size)\n",
        "            x[j]=img\n",
        "        y=np.zeros((self.batch_size,)+self.img_size+(1,),dtype = \"uint8\")\n",
        "        for j,path in enumerate(batch_label_paths):\n",
        "            img = load_img(path,target_size = self.img_size,color_mode = \"grayscale\")\n",
        "            y[j]=np.expand_dims(img,2)\n",
        "            y[j]-=1\n",
        "        return x,y\n",
        "\n",
        "def make_model(img_size,num_classes):\n",
        "    inputs = keras.Input(shape = img_size+(3,))\n",
        "\n",
        "\n",
        "    # U-net의 다운 샘플링(축소경로)\n",
        "    x = layers.Conv2D(32,3,strides=2,padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    previous_block_activation = x\n",
        "\n",
        "    for filters in [64,128,256]:\n",
        "        x = layers.Activation('relu')(x)\n",
        "        x = layers.SeparableConv2D(filters,3,padding = 'same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation('relu')(x)\n",
        "        x = layers.SeparableConv2D(filters,3,padding = 'same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D(3,strides=2,padding = 'same')(x)\n",
        "        residual = layers.Conv2D(filters,1,strides=2,padding='same')(previous_block_activation)\n",
        "        x = layers.add([x,residual])\n",
        "        previous_block_activation = x\n",
        "\n",
        "    # U-net 업 샘플링(확대 경로)\n",
        "    for filters in [256 ,128, 64 ,32]:\n",
        "        x = layers.Activation('relu')(x)\n",
        "        x = layers.Conv2DTranspose(filters,3,padding = 'same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation('relu')(x)\n",
        "        x = layers.Conv2DTranspose(filters,3,padding = 'same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters,1,padding = 'same')(residual)\n",
        "        x = layers.add([x,residual])\n",
        "        previous_block_activation = x\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes,3,activation = 'softmax',padding = 'same')(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = make_model(img_siz,n_class)\n",
        "\n",
        "random.Random(1).shuffle(img_paths)\n",
        "random.Random(1).shuffle(label_paths)\n",
        "test_samples = int(len(img_paths)*0.1)\n",
        "train_img_paths = img_paths[:-test_samples]\n",
        "train_label_paths = label_paths[:-test_samples]\n",
        "test_img_paths = img_paths[-test_samples:]\n",
        "test_label_paths = label_paths[-test_samples:]\n",
        "\n",
        "train_gen = OxfordPets(batch_siz,img_siz,train_img_paths,train_label_paths)\n",
        "test_gen = OxfordPets(batch_siz,img_siz,test_img_paths,test_label_paths)\n",
        "\n",
        "model.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
        "cb = [keras.callbacks.ModelCheckpoint('oxford_seg.h5',save_best_only=True)]\n",
        "model.fit(train_gen,epochs = 20,validation_data = test_gen,callbacks = cb)\n",
        "\n",
        "preds = model.predict(test_gen)\n",
        "\n",
        "cv2_imshow(cv.imread(test_img_paths[0]))\n",
        "cv2_imshow(cv.imread(test_label_paths[0])*64)\n",
        "cv2_imshow(preds[0])\n",
        "\n",
        "cv.waitKey()\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "WL-Pzw-HXDwS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}